{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd64c83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 1. Import libraries\n",
    "# -------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Load dataset (example)\n",
    "# -------------------------------\n",
    "# You can replace this with your dataset\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "data = fetch_california_housing(as_frame=True)\n",
    "df = data.frame\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Select a small sample (10% for initial testing)\n",
    "# -------------------------------\n",
    "sample_df = df.sample(frac=0.1, random_state=42)\n",
    "\n",
    "# Features and target\n",
    "X = sample_df.drop(columns='MedHouseVal')\n",
    "y = sample_df['MedHouseVal']\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Identify numerical and categorical columns\n",
    "# -------------------------------\n",
    "# In this dataset all columns are numeric\n",
    "num_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include='object').columns.tolist()  # if you have categorical features\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Preprocessing\n",
    "# -------------------------------\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_cols),\n",
    "        ('cat', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Define models to compare\n",
    "# -------------------------------\n",
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'Ridge': Ridge(alpha=1.0),\n",
    "    'Lasso': Lasso(alpha=0.1),\n",
    "    'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# -------------------------------\n",
    "# 7. Cross-validation\n",
    "# -------------------------------\n",
    "cv_results = []\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Create a pipeline\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('regressor', model)])\n",
    "    \n",
    "    # Compute CV scores (negative MSE)\n",
    "    scores = cross_val_score(pipeline, X, y, cv=kf, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    # Convert to positive MSE\n",
    "    mse_scores = -scores\n",
    "    rmse_scores = np.sqrt(mse_scores)\n",
    "    \n",
    "    cv_results.append({\n",
    "        'Model': name,\n",
    "        'RMSE Mean': rmse_scores.mean(),\n",
    "        'RMSE Std': rmse_scores.std()\n",
    "    })\n",
    "\n",
    "# -------------------------------\n",
    "# 8. Show results\n",
    "# -------------------------------\n",
    "cv_df = pd.DataFrame(cv_results).sort_values(by='RMSE Mean')\n",
    "print(cv_df)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
